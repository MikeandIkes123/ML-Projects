{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Diabetes\n",
    "\n",
    "In this part of the assignment, you will build a predictive model for diabetes disease progression in the next year based on current observed features of disease symptoms. \n",
    "\n",
    "**Learning objectives.** You will:\n",
    "1. Train and test a linear model using ordinary least squares regression. \n",
    "2. Apply regularization, specifically LASSO, to build a sparse model.\n",
    "\n",
    "The following code will download and preview three examples of the data. The ten features are as follows (in order):\n",
    "\n",
    "- age age in years\n",
    "- sex\n",
    "- bmi body mass index\n",
    "- bp average blood pressure\n",
    "- s1 tc, total serum cholesterol\n",
    "- s2 ldl, low-density lipoproteins\n",
    "- s3 hdl, high-density lipoproteins\n",
    "- s4 tch, total cholesterol / HDL\n",
    "- s5 ltg, log of serum triglycerides level\n",
    "- s6 glu, blood sugar level\n",
    "\n",
    "The target value is a quantiative measure of disease progression after 1 year, where larger numbers are worse.\n",
    "\n",
    "The code stores the feature matrix `X` as a two-dimensional NumPy array where each row corresponds to a data point and each column is a feature. The target value is stored as a one-dimensional NumPy array `y` where the index `i` element of `y` correpsonds to the row `i` data point of `X`.\n",
    "\n",
    "Your overall goal in this part is to build and evaluate a linear model to predict the target variable `y` as a function of the ten features in `X`, and to identify which features are more significant for predicting `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "[[ 59.       2.      32.1    101.     157.      93.2     38.       4.\n",
      "    4.8598  87.    ]\n",
      " [ 48.       1.      21.6     87.     183.     103.2     70.       3.\n",
      "    3.8918  69.    ]\n",
      " [ 72.       2.      30.5     93.     156.      93.6     41.       4.\n",
      "    4.6728  85.    ]]\n",
      "[151.  75. 141.]\n"
     ]
    }
   ],
   "source": [
    "# Run but DO NOT MODIFY this code\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes(scaled = False)\n",
    "print(diabetes.feature_names)\n",
    "\n",
    "# Get the feature data and target variable\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Preview the first 3 data points\n",
    "print(X[:3])\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Randomly split the input data into a [train and test partition](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with 30% of the data reserved for testing. Use a random seed of `2024` for reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write task 1 code here\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Build a baseline prediction by computing the [average](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) target value of the training data. Evaluate the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) between the baseline and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 78.17581726028506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "baseline_prediction = np.mean(y_train)\n",
    "y_baseline = np.full(y_test.shape, baseline_prediction) #need to convert\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_baseline))\n",
    "\n",
    "print(f\"Baseline RMSE: {rmse_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Build a linear predictive model using [ordinary least squares regression](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares) fit on the training data. \n",
    "\n",
    "Evaluate the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) of the model on **both** the training data **and** the test data (that is, the training error and the generalization error). Report both and briefly discuss the results: Do you observe underfitting or overfitting?\n",
    "\n",
    "Note that the model predictions on the test data may not be perfect, but they should improve meaningfully over the simple baseline from Task 2 or something is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 52.85235480118789\n",
      "Test RMSE: 55.61674711723449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)  \n",
    "y_test_pred = reg.predict(X_test)    \n",
    "\n",
    "\n",
    "train_rmse = np.sqrt(mse(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mse(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observe overfitting, since the Training RMSE (52.85) is lower than the Test RMSE (55.61). This is because the model  performs better on the training set but slightly worse on unseen data like the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "If your goal is to understand which of the input features in `X` are most important for predicting the target `y`, the linear model you built in task 3 may not be very helpful. Build a new linear model using [Lasso regression](https://scikit-learn.org/stable/modules/linear_model.html#lasso) that achieves comparable generalization error as the task 3 model using ordinary least squares regression (within 10% of the root mean squared error on the test set), but with **0 for at least three of the model coefficients** (that is, the model does not use these features to make predictions). \n",
    "\n",
    "You may need to try multiple vaues of the `alpha` *hyperparameter* to find a model that satisfies both the error and *sparsity* constraints (that at least three of the coefficients are 0). Nevertheless, you should only evaluate error on the test dataset **once**. Show your work for how you find a good `alpha` in code and explain your work in English below. Standard approaches would be to split the training data into a train and validation set, or to use [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html) on the training data.\n",
    "\n",
    "For your final fit Lasso model with the chosen `alpha`, report the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) on the test data. Also report the model coefficients and use this to explain which features (see their names/interpretations above) seem less important for predicting the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha without worrying about sparsity: 0.1519911082952933\n",
      "Best alpha with error and sparsity: 3.944206059437656\n",
      "Test RMSE for Lasso regression with best alpha: 57.5360272634609\n",
      "Model coefficients:\n",
      "[ 0.         -3.4484256   5.97353445  1.27211544  1.11532614 -1.31490185\n",
      " -1.93769332  0.          0.          0.1748216 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alphas = np.logspace(-4, 1, 100)\n",
    "lasso = Lasso(max_iter=10000) \n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "grid_search = GridSearchCV(lasso, param_grid, scoring='neg_root_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best alpha without worrying about sparsity: {grid_search.best_params_['alpha']}\")\n",
    "\n",
    "final_alpha = None\n",
    "final_coef = None\n",
    "\n",
    "for alpha in grid_search.cv_results_['params']:\n",
    "    lasso.set_params(alpha=alpha['alpha'])\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    if np.sum(lasso.coef_ == 0) >= 3: \n",
    "        final_alpha = alpha['alpha']\n",
    "        final_coef = lasso.coef_\n",
    "        break  # Stop as soon as we find a valid model\n",
    "\n",
    "if final_alpha:\n",
    "    lasso.set_params(alpha=final_alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lasso.predict(X_test)  # Predict using the test set\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"Best alpha with error and sparsity: {final_alpha}\")\n",
    "    print(f\"Test RMSE for Lasso regression with best alpha: {test_rmse}\")\n",
    "    print(\"Model coefficients:\")\n",
    "    print(final_coef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code uses Lasso regression to find the best value of the regularization parameter, alpha, by balancing prediction error and sparsity. A GridSearchCV process tests multiple alpha values and derives an alpha value of 0.001 without worrying about error or sparsity. However, once I loop through each alpha, I want to select the first model with fewer than three zero coefficients. After identifying the best alpha, the model is fit to the training data, and its performance is evaluated on the test set only once, calculating the final RMSE while also accounting for the three zero coefficients.  In this case, since the coefficients for age, HDL levels, and Total Cholesterol/HDL ratio are zero, it means these features are not contributing to the prediction, highlighting their lack of importance in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
