{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Cancer\n",
    "\n",
    "In this part of the assignment, you will build a predictive model to classify a given breast tumor as cancer or not based on exam measurements of the size and shape of the tumor. \n",
    "\n",
    "**Learning objectives.** You will:\n",
    "1. Train and test a logistic regression model for binary classification. \n",
    "2. Evaluate and interpret a range of metrics including the confusion matrix, precision, recall, and ROC curve.\n",
    "3. Look for evidence of overfitting and perform hyperparameter selection to choose a regularization weight on a validation set to mitigate overfitting.\n",
    "4. Fit and discuss an interpretable shallow decision tree model.\n",
    "\n",
    "The following code will download all of the data, print the feature names, and preview one example. The target value is binary: either `1` or `0` depending on whether the tumor is malignant or benign.\n",
    "\n",
    "The code stores the feature matrix `X` as a two-dimensional NumPy array where each row corresponds to a data point and each column is a feature. The target value is stored as a one-dimensional NumPy array `y` where the index `i` element of `y` correpsonds to the row `i` data point of `X`.\n",
    "\n",
    "Your overall goal in this part is to build and evaluate a logistic model to predict the target variable `y` as a function of the ten features in `X` by predicting the probability that a given tumor is malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Run but DO NOT MODIFY this code\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the diabetes dataset\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.feature_names)\n",
    "\n",
    "# Get the feature data and target variable\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Preview the first data point\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Randomly split the input data into a [train and test partition](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with at least 30% of the data reserved for testing. Use a random seed of `2024` for reproducibility of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Build and evaluate a baseline model as follows. Calculate the proportion of the training data with target `1`, call this proportion `p`. For each example in the test data, randomly predict `1` with probability `p` and `0` otherwise. Set a random seed of `2024` before starting for reproducibility.\n",
    "\n",
    "Compute and visualize the [confusion matrix](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#create-confusionmatrixdisplay) of the resulting predictions on the test data. Also compute and report the [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) and [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) of the predictions on the test data. \n",
    "\n",
    "Briefly interpret the confusion matrix, precision, and recall. What do these quantities mean in the context of the predictive task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.97\n",
      "Recall: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtLElEQVR4nO3deXxU9b3/8fdkmySQhM1MCAQIEBYFFQNFcAGrYFEplN91KVhRwaqomKKiXFyilkRoixG4IOAtcK20+nDB5SolVcEFUUCwFhCrBghLDMiSkIQsM+f3R2SuYwBncmaYOXNez8fjPB6dM2f5gCmffD7f7zlfh2EYhgAAgCXFhDsAAADQfCRyAAAsjEQOAICFkcgBALAwEjkAABZGIgcAwMJI5AAAWFhcuAMww+PxaO/evUpJSZHD4Qh3OACAABmGocrKSmVmZiomJnS15bFjx1RXV2f6OgkJCUpMTAxCRMFj6US+d+9eZWVlhTsMAIBJpaWl6tixY0iufezYMWV3bqmycrfpa2VkZKikpCSikrmlE3lKSookqfszeYpNdoY5GiA02o/9ItwhACHToHp9oDe9/56HQl1dncrK3dq5sYtSU5pf9VdUetQ5d4fq6upI5MFyvJ0em+wkkSNqxTniwx0CEDrfvyT8dAyPtkxxqGVK8+/jUWQO4Vo6kQMA4C+34ZHbxOoibsMTvGCCiEQOALAFjwx51PxMbubcUOLxMwAALIyKHABgCx55ZKY5bu7s0CGRAwBswW0YchvNb4+bOTeUaK0DAGBhVOQAAFuI1sluJHIAgC14ZMgdhYmc1joAABZGRQ4AsAVa6wAAWBiz1gEAQMShIgcA2ILn+83M+ZGIRA4AsAW3yVnrZs4NJRI5AMAW3IZMrn4WvFiCiTFyAAAsjIocAGALjJEDAGBhHjnklsPU+ZGI1joAABZGRQ4AsAWP0biZOT8SkcgBALbgNtlaN3NuKNFaBwDAwqjIAQC2EK0VOYkcAGALHsMhj2Fi1rqJc0OJ1joAABZGRQ4AsAVa6wAAWJhbMXKbaES7gxhLMJHIAQC2YJgcIzcYIwcAAMFGRQ4AsAXGyAEAsDC3ESO3YWKMPEJf0UprHQAAC6MiBwDYgkcOeUzUrx5FZklOIgcA2EK0jpHTWgcAwMKoyAEAtmB+shutdQAAwqZxjNzEoim01gEAQLBRkQMAbMFj8l3rzFoHACCMGCMHAMDCPIqJyufIGSMHAMDCqMgBALbgNhxym1iK1My5oUQiBwDYgtvkZDc3rXUAABBsVOQAAFvwGDHymJi17mHWOgAA4UNrHQAARBwqcgCALXhkbua5J3ihBBWJHABgC+ZfCBOZTezIjAoAAPiFihwAYAvm37UembUviRwAYAvRuh45iRwAYAvRWpFHZlQAAMAvVOQAAFsw/0KYyKx9SeQAAFvwGA55zDxHHqGrn0XmrxcAAMAvVOQAAFvwmGytR+oLYUjkAABbML/6WWQm8siMCgAA+IWKHABgC2455DbxUhcz54YSiRwAYAu01gEAQMShIgcA2IJb5trj7uCFElQkcgCALURra51EDgCwBRZNAQAAfmtoaNCDDz6o7OxsJSUlqWvXrnrsscfk8Xi8xxiGofz8fGVmZiopKUlDhw7Vli1bAroPiRwAYAvG9+uRN3czAhxfnzlzpp5++mnNmzdP27Zt06xZs/SHP/xBc+fO9R4za9YszZ49W/PmzdP69euVkZGhYcOGqbKy0u/70FoHANhCsFrrFRUVPvudTqecTmeT4z/66CONGjVKV155pSSpS5cu+utf/6oNGzZIaqzGi4qKNH36dI0ZM0aStGzZMrlcLi1fvly33nqrX3FRkQMAEICsrCylpaV5t8LCwhMed+GFF+rtt9/Wl19+KUn67LPP9MEHH+iKK66QJJWUlKisrEzDhw/3nuN0OjVkyBCtXbvW73ioyAEAthCsZUxLS0uVmprq3X+ialyS7r//fh05ckS9evVSbGys3G63ZsyYoV//+teSpLKyMkmSy+XyOc/lcmnnzp1+x0UiBwDYgtvk6mfHz01NTfVJ5Cfz/PPP6y9/+YuWL1+us846S5s3b1ZeXp4yMzM1fvx473EOh+8vF4ZhNNl3KiRyAABC4L777tMDDzyg6667TpLUt29f7dy5U4WFhRo/frwyMjIkNVbm7du3955XXl7epEo/FcbIAQC2cLy1bmYLRHV1tWJifNNsbGys9/Gz7OxsZWRkqLi42Pt9XV2d1qxZo8GDB/t9HypyAIAteBQjj4n6NdBzR44cqRkzZqhTp04666yztGnTJs2ePVs333yzpMaWel5engoKCpSTk6OcnBwVFBQoOTlZY8eO9fs+JHIAAEJg7ty5euihhzRp0iSVl5crMzNTt956qx5++GHvMVOnTlVNTY0mTZqkQ4cOaeDAgVq1apVSUlL8vo/DMAwjFH+A06GiokJpaWnqufx+xSafeNYgYHWZv9oa7hCAkGkw6rVar+rIkSN+TSBrjuO54vb3x8jZMr7Z16k9Wq8FF70c0libg4ocAGALwXr8LNKQyAEAtmCYXP3MYNEUAAAQbFTkAABbcMshd4ALn/z4/EhEIgcA2ILHMDfO7YnQqeG01gEAsDAqcpxQzHf1Sv2fciV+elSq88idmaDDd2aqvltSk2PTFuxVi1WHdeRml6pGtg1DtIA5V91wQFfe8J1cWXWSpJ3bE/Xcky5teDdyHjGCeR6Tk93MnBtKJHI04TjqVrtpO1TXN1nfPdRJnlaxii2rkyc5tsmxiR9XKOHLGrnb8KME69q/L15/LmivvTsa30cx7OqDyl+yQ3cM76GdXyaGOToEi0cOeUyMc5s5N5TC/uvF/PnzlZ2drcTEROXm5ur9998Pd0i21/LlA3K3i9PhuzqovkeS3OkJqju7pdztE3yOi/muXmmLy3Todx1kxEbmDzjgj4+L07T+nVTt+capPd84tXRmex2rilGv3Kpwhwb8pLAm8ueff155eXmaPn26Nm3apIsuukgjRozQrl27whmW7SWur1R99yS1nlUq1/jtOmPKN0pedcj3II+h1kV7dHRUWzV0omJB9IiJMTRk1CE5kz3atqFFuMNBELkNh+ktEoW1Hzp79mxNmDBBEydOlCQVFRXp73//uxYsWKDCwsJwhmZrcd/WK27lIR39ZRtV/kc7Jfz7mNL+u0xGvEM1l7SSJLV85TsZsQ5VXdUmvMECQdKlV42KXv9KCU6Paqpi9NiELtr1b35JjSaMkQdZXV2dNm7cqAceeMBn//Dhw7V27doTnlNbW6va2lrv54qKipDGaFuGofpuSaq8vnE93IauSYorrVWLlYdUc0krxX9doxZvfKf9f+oqOSLzN1QgULu/dmrSsB5qkerWhVce0b1P7dJ9Y7qTzBHxwpbIDxw4ILfb3WTxdJfLpbKyshOeU1hYqEcfffR0hGdr7tbxqs/yXYSmoWOCkj5q/MUpYWu1Yo645brl397vHR4pdem3avH6QZUvyjmt8QLB0FAf453s9u9/JqvnudUaPXG/5tyfFebIECwemXzXeoROdgv7VGPHjyo6wzCa7Dtu2rRpmjJlivdzRUWFsrL4P1mw1fVKUtyeWp99cXvr5D6jcdWg6iFpqj3bd+yw7WO7VD0kTdWXtjpdYQIhF58QoW8AQbMYJmetGyRyX+3atVNsbGyT6ru8vLxJlX6c0+mU08lypaFWNbKt2k0rUcsX96vmgjQl/LtGyasO6cjtmZIkIzVODam+PzpGrEOe1nFyd+C/D6znpgf2af07Kdq/N0FJLd0aOuqwzh58VA+O6xru0BBErH4WZAkJCcrNzVVxcbF+9atfefcXFxdr1KhR4QoLkupzknTw/iyl/qVcKS8cUEN6vCpuzlDNkLRwhwaERKszGnTf3F1qk96g6spYlWxL1IPjuurT91LCHRrwk8LaWp8yZYp+85vfqH///ho0aJAWLVqkXbt26bbbbgtnWJBUOyBF+wf4/48Y4+KwsifvYYjODpi1HgLXXnutvvvuOz322GPat2+f+vTpozfffFOdO3cOZ1gAgChEaz1EJk2apEmTJoU7DAAALCnsiRwAgNMhWt+1TiIHANhCtLbWI3PkHgAA+IWKHABgC9FakZPIAQC2EK2JnNY6AAAWRkUOALCFaK3ISeQAAFswZO4RskhdQodEDgCwhWityBkjBwDAwqjIAQC2EK0VOYkcAGAL0ZrIaa0DAGBhVOQAAFuI1oqcRA4AsAXDcMgwkYzNnBtKtNYBALAwKnIAgC2wHjkAABYWrWPktNYBALAwKnIAgC1E62Q3EjkAwBaitbVOIgcA2EK0VuSMkQMAYGFU5AAAWzBMttYjtSInkQMAbMGQZBjmzo9EtNYBALAwKnIAgC145JCDN7sBAGBNzFoHAAARh4ocAGALHsMhBy+EAQDAmgzD5Kz1CJ22TmsdAAALoyIHANhCtE52I5EDAGyBRA4AgIVF62Q3xsgBALAwKnIAgC1E66x1EjkAwBYaE7mZMfIgBhNEtNYBALAwKnIAgC0wax0AAAszZG5N8QjtrNNaBwDAyqjIAQC2QGsdAAAri9LeOokcAGAPJityRWhFzhg5AAAWRkUOALCFaH2zGxU5AMAWjk92M7MFas+ePbr++uvVtm1bJScn69xzz9XGjRt/EJOh/Px8ZWZmKikpSUOHDtWWLVsCugeJHACAEDh06JAuuOACxcfH66233tLWrVv1pz/9Sa1atfIeM2vWLM2ePVvz5s3T+vXrlZGRoWHDhqmystLv+9BaBwDYg+EwN2Ht+3MrKip8djudTjmdziaHz5w5U1lZWVqyZIl3X5cuXf7vcoahoqIiTZ8+XWPGjJEkLVu2TC6XS8uXL9ett97qV1hU5AAAWzg+Rm5mk6SsrCylpaV5t8LCwhPe77XXXlP//v119dVXKz09Xf369dPixYu935eUlKisrEzDhw/37nM6nRoyZIjWrl3r95+LihwAgACUlpYqNTXV+/lE1bgkffPNN1qwYIGmTJmi//zP/9Qnn3yiyZMny+l06oYbblBZWZkkyeVy+Zzncrm0c+dOv+MhkQMA7CFIL4RJTU31SeQn4/F41L9/fxUUFEiS+vXrpy1btmjBggW64YYbvMc5HL7tfsMwmuw7FVrrAABbON2z1tu3b68zzzzTZ1/v3r21a9cuSVJGRoYkeSvz48rLy5tU6afiV0U+Z84cvy84efJkv48FACBaXXDBBdq+fbvPvi+//FKdO3eWJGVnZysjI0PFxcXq16+fJKmurk5r1qzRzJkz/b6PX4n8ySef9OtiDoeDRA4AiFyn8aUuv/vd7zR48GAVFBTommuu0SeffKJFixZp0aJFkhpzZl5engoKCpSTk6OcnBwVFBQoOTlZY8eO9fs+fiXykpKS5v0pAACIEKd79bMBAwbolVde0bRp0/TYY48pOztbRUVFGjdunPeYqVOnqqamRpMmTdKhQ4c0cOBArVq1SikpKX7fp9mT3erq6lRSUqJu3bopLo45cwCACBeG1c+uuuoqXXXVVSf93uFwKD8/X/n5+c0OK+DJbtXV1ZowYYKSk5N11llneQftJ0+erCeeeKLZgQAAgMAFnMinTZumzz77TKtXr1ZiYqJ3/2WXXabnn38+qMEBABA8jiBskSfgnviKFSv0/PPP6/zzz/d5zu3MM8/U119/HdTgAAAImjC01k+HgCvy/fv3Kz09vcn+qqqqgB5gBwAA5gWcyAcMGKD//d//9X4+nrwXL16sQYMGBS8yAACCyQjCFoECbq0XFhbqF7/4hbZu3aqGhgY99dRT2rJliz766COtWbMmFDECAGBekFY/izQBV+SDBw/Whx9+qOrqanXr1k2rVq2Sy+XSRx99pNzc3FDECAAATqJZD4D37dtXy5YtC3YsAACEzA+XIm3u+ZGoWYnc7XbrlVde0bZt2+RwONS7d2+NGjWKF8MAACJXlM5aDzjz/utf/9KoUaNUVlamnj17Smp8CfwZZ5yh1157TX379g16kAAA4MQCHiOfOHGizjrrLO3evVuffvqpPv30U5WWlurss8/Wb3/721DECACAeccnu5nZIlDAFflnn32mDRs2qHXr1t59rVu31owZMzRgwICgBgcAQLA4jMbNzPmRKOCKvGfPnvr222+b7C8vL1f37t2DEhQAAEEXpc+R+5XIKyoqvFtBQYEmT56sF198Ubt379bu3bv14osvKi8vL6CF0AEAgHl+tdZbtWrl8/pVwzB0zTXXePcZ38/JHzlypNxudwjCBADApCh9IYxfifzdd98NdRwAAISWnR8/GzJkSKjjAAAAzdDsN7hUV1dr165dqqur89l/9tlnmw4KAICgs3NF/kP79+/XTTfdpLfeeuuE3zNGDgCISFGayAN+/CwvL0+HDh3SunXrlJSUpJUrV2rZsmXKycnRa6+9FooYAQDASQRckb/zzjt69dVXNWDAAMXExKhz584aNmyYUlNTVVhYqCuvvDIUcQIAYE6UzloPuCKvqqpSenq6JKlNmzbav3+/pMYV0T799NPgRgcAQJAcf7ObmS0SNevNbtu3b5cknXvuuVq4cKH27Nmjp59+Wu3btw96gAAA4OQCbq3n5eVp3759kqRHHnlEl19+uZ577jklJCRo6dKlwY4PAIDgiNLJbgEn8nHjxnn/d79+/bRjxw598cUX6tSpk9q1axfU4AAAwKk1+zny45KTk3XeeecFIxYAAELGIZOrnwUtkuDyK5FPmTLF7wvOnj272cEAAIDA+JXIN23a5NfFfriwyumUeVOJ4hzxYbk3EGor924OdwhAyFRUetS6x2m6WZQ+fsaiKQAAe4jSyW4BP34GAAAih+nJbgAAWEKUVuQkcgCALZh9O1vUvNkNAABEDipyAIA9RGlrvVkV+bPPPqsLLrhAmZmZ2rlzpySpqKhIr776alCDAwAgaIwgbBEo4ES+YMECTZkyRVdccYUOHz4st9stSWrVqpWKioqCHR8AADiFgBP53LlztXjxYk2fPl2xsbHe/f3799fnn38e1OAAAAiWaF3GNOAx8pKSEvXr16/JfqfTqaqqqqAEBQBA0EXpm90Crsizs7O1efPmJvvfeustnXnmmcGICQCA4IvSMfKAK/L77rtPd9xxh44dOybDMPTJJ5/or3/9qwoLC/XMM8+EIkYAAHASASfym266SQ0NDZo6daqqq6s1duxYdejQQU899ZSuu+66UMQIAIBp0fpCmGY9R37LLbfolltu0YEDB+TxeJSenh7suAAACK4ofY7c1Ath2rVrF6w4AABAMwScyLOzs0+57vg333xjKiAAAELC7CNk0VKR5+Xl+Xyur6/Xpk2btHLlSt13333BigsAgOCitd7o7rvvPuH+//qv/9KGDRtMBwQAAPwXtNXPRowYoZdeeilYlwMAILh4jvzUXnzxRbVp0yZYlwMAIKh4/Ox7/fr185nsZhiGysrKtH//fs2fPz+owQEAgFMLOJGPHj3a53NMTIzOOOMMDR06VL169QpWXAAAwA8BJfKGhgZ16dJFl19+uTIyMkIVEwAAwRels9YDmuwWFxen22+/XbW1taGKBwCAkIjWZUwDnrU+cOBAbdq0KRSxAACAAAU8Rj5p0iTdc8892r17t3Jzc9WiRQuf788+++ygBQcAQFBFaFVtht+J/Oabb1ZRUZGuvfZaSdLkyZO93zkcDhmGIYfDIbfbHfwoAQAwK0rHyP1O5MuWLdMTTzyhkpKSUMYDAAAC4HciN4zGX0U6d+4csmAAAAgVXggjnXLVMwAAIprdW+uS1KNHj59M5gcPHjQVEAAA8F9AifzRRx9VWlpaqGIBACBkaK1Luu6665Senh6qWAAACJ0oba37/UIYxscBAIg8Ac9aBwDAkqK0Ivc7kXs8nlDGAQBASDFGDgCAlUVpRR7woikAACBykMgBAPZgBGFrpsLCQjkcDuXl5f1fOIah/Px8ZWZmKikpSUOHDtWWLVsCvjaJHABgC+Faj3z9+vVatGhRk9VBZ82apdmzZ2vevHlav369MjIyNGzYMFVWVgZ0fRI5AAABqKio8Nlqa2tPeuzRo0c1btw4LV68WK1bt/buNwxDRUVFmj59usaMGaM+ffpo2bJlqq6u1vLlywOKh0QOALCHILXWs7KylJaW5t0KCwtPess77rhDV155pS677DKf/SUlJSorK9Pw4cO9+5xOp4YMGaK1a9cG9Mdi1joAwBaC9fhZaWmpUlNTvfudTucJj//b3/6mTz/9VOvXr2/yXVlZmSTJ5XL57He5XNq5c2dAcZHIAQAIQGpqqk8iP5HS0lLdfffdWrVqlRITE0963I/fmmoYRsBvUqW1DgCwh9M4a33jxo0qLy9Xbm6u4uLiFBcXpzVr1mjOnDmKi4vzVuLHK/PjysvLm1TpP4VEDgCwh9OYyC+99FJ9/vnn2rx5s3fr37+/xo0bp82bN6tr167KyMhQcXGx95y6ujqtWbNGgwcPDuiPRWsdAIAgS0lJUZ8+fXz2tWjRQm3btvXuz8vLU0FBgXJycpSTk6OCggIlJydr7NixAd2LRA4AsAXH95uZ84Np6tSpqqmp0aRJk3To0CENHDhQq1atUkpKSkDXIZEDAOwhzO9aX716tc9nh8Oh/Px85efnm7ouiRwAYAvRuvoZk90AALAwKnIAgD1E6TKmJHIAgH1EaDI2g9Y6AAAWRkUOALCFaJ3sRiIHANhDlI6R01oHAMDCqMgBALZAax0AACujtQ4AACINFTkAwBZorQMAYGVR2lonkQMA7CFKEzlj5AAAWBgVOQDAFhgjBwDAymitAwCASENFDgCwBYdhyGE0v6w2c24okcgBAPZAax0AAEQaKnIAgC0wax0AACujtQ4AACINFTkAwBZorQMAYGVR2lonkQMAbCFaK3LGyAEAsDAqcgCAPdBaBwDA2iK1PW4GrXUAACyMihwAYA+G0biZOT8CkcgBALbArHUAABBxqMgBAPbArHUAAKzL4WnczJwfiWitAwBgYVTk+EnX371b1+ft9dl3cH+8xv6sX5giAsypPhqjZbPaa+1baTr8XZy6nVWj2x/frZ7n1kiSDu2P03/PyNTGNSmqOhKrPucf1R2/360OXevCHDlMobUOO9uxPUnTru/p/ezxOMIYDWDOk/dkacf2RE2du1NtXPV656U2euDa7lq8+gu1zajXozdnKzbOUP6Sb5Tc0qOXF53R+P2aL5SYHKH9VfwkZq2HwHvvvaeRI0cqMzNTDodDK1asCGc4OAW326FDBxK825GD8eEOCWiW2hqHPnizlSY+uE99z69Sh+w6/ebeMmVk1emN/2mrPd84tW1jC931RGOFntW9VncW7lZNdYzefaVVuMOHGcefIzezRaCwJvKqqiqdc845mjdvXjjDgB86dDmm59Zt0tL3NuuBOV8pI+tYuEMCmsXtdsjjdijB6VtZO5M82vJJS9XXNXabfvh9bKwUH29oy/qWpzVWwB9hba2PGDFCI0aM8Pv42tpa1dbWej9XVFSEIiz8yBebW+oP93TVnpJEtW5Xr1/fuVezX9qmW4f3UeVhKnNYS3JLj3rnVml5UYY65exQqzMatHpFa33xabI6ZNcqq/sxuTrW6c+F7XX3zN1KTPbo5YVn6GB5vA5+y2ikldFajwCFhYVKS0vzbllZWeEOyRY2rGmlD1e20Y7tydr0YZoeurmHJGnY/zsQ5siA5pk6d6cMQxp7Xh9d1eUcrfjvdrrkV4cUEyvFxUsPPVOiPV8n6j/O7Ktfdjtbn33UUgN+XqGY2HBHDlOMIGwRyFK/Xk6bNk1Tpkzxfq6oqCCZh0FtTax2bE9SZpfanz4YiECZXer0x5e/0rHqGFVVxqitq0Ezbu2sjE6NP9M5Z9dowT+2q6oiRvX1DrVq69bkK3PU4+zqMEcONGWpitzpdCo1NdVnw+kXn+BRVrcaHSynrQ5rS0z2qK2rQZWHY7VxTaoGXe47XNci1aNWbd3a802C/v1ZcpPvYS3HW+tmtkhkqYoc4THxP3fp47dbqXyPU62+HyNPbunWP15uF+7QgGbZsDpFhiFldavVnpIEPfN4B3XsdkzDr/1OkvTe62lKa+tWeoc6lWxL1NMPd9SgXxxR7tDKMEcOU1j9DHbVLqNODzz1tVJbN+jIwTh9samlfjfmLJXvcYY7NKBZqipitaSwvQ7si1dKK7cuuOKwbnpgn+K+bzId/DZeC/M76PCBOLVJb9BlVx/U2Lxvwxs0cBJhTeRHjx7VV1995f1cUlKizZs3q02bNurUqVMYI8MPPTG5e7hDAIJqyC8Pa8gvD5/0+9ETD2j0RCZzRptonbUe1kS+YcMGXXLJJd7PxyeyjR8/XkuXLg1TVACAqMQrWoNv6NChMiJ0zAEAACtgjBwAYAu01gEAsDKP0biZOT8CkcgBAPYQpWPklnohDAAA8EVFDgCwBYdMjpEHLZLgIpEDAOwhSt/sRmsdAAALoyIHANgCj58BAGBlzFoHAACRhoocAGALDsOQw8SENTPnhhKJHABgD57vNzPnRyBa6wAAWBgVOQDAFmitAwBgZVE6a51EDgCwB97sBgAA/FVYWKgBAwYoJSVF6enpGj16tLZv3+5zjGEYys/PV2ZmppKSkjR06FBt2bIloPuQyAEAtnD8zW5mtkCsWbNGd9xxh9atW6fi4mI1NDRo+PDhqqqq8h4za9YszZ49W/PmzdP69euVkZGhYcOGqbKy0u/70FoHANhDkFrrFRUVPrudTqecTmeTw1euXOnzecmSJUpPT9fGjRt18cUXyzAMFRUVafr06RozZowkadmyZXK5XFq+fLluvfVWv8KiIgcAIABZWVlKS0vzboWFhX6dd+TIEUlSmzZtJEklJSUqKyvT8OHDvcc4nU4NGTJEa9eu9TseKnIAgC04PI2bmfMlqbS0VKmpqd79J6rGf8wwDE2ZMkUXXnih+vTpI0kqKyuTJLlcLp9jXS6Xdu7c6XdcJHIAgD0EqbWemprqk8j9ceedd+qf//ynPvjggybfORyOH93GaLLvVGitAwAQQnfddZdee+01vfvuu+rYsaN3f0ZGhqT/q8yPKy8vb1KlnwqJHABgD0YQtkBuZxi688479fLLL+udd95Rdna2z/fZ2dnKyMhQcXGxd19dXZ3WrFmjwYMH+30fWusAAFs43a9oveOOO7R8+XK9+uqrSklJ8VbeaWlpSkpKksPhUF5engoKCpSTk6OcnBwVFBQoOTlZY8eO9fs+JHIAAEJgwYIFkqShQ4f67F+yZIluvPFGSdLUqVNVU1OjSZMm6dChQxo4cKBWrVqllJQUv+9DIgcA2MNpfkWr4cfxDodD+fn5ys/Pb2ZQJHIAgF0YMremeGS+ap1EDgCwh2hdxpRZ6wAAWBgVOQDAHgyZHCMPWiRBRSIHANgD65EDAIBIQ0UOALAHjyT/X2F+4vMjEIkcAGALzFoHAAARh4ocAGAPUTrZjUQOALCHKE3ktNYBALAwKnIAgD1EaUVOIgcA2AOPnwEAYF08fgYAACIOFTkAwB4YIwcAwMI8huQwkYw9kZnIaa0DAGBhVOQAAHugtQ4AgJWZTOSKzEROax0AAAujIgcA2AOtdQAALMxjyFR7nFnrAAAg2KjIAQD2YHgaNzPnRyASOQDAHhgjBwDAwhgjBwAAkYaKHABgD7TWAQCwMEMmE3nQIgkqWusAAFgYFTkAwB5orQMAYGEejyQTz4J7IvM5clrrAABYGBU5AMAeaK0DAGBhUZrIaa0DAGBhVOQAAHuI0le0ksgBALZgGB4ZJlYwM3NuKJHIAQD2YBjmqmrGyAEAQLBRkQMA7MEwOUYeoRU5iRwAYA8ej+QwMc4doWPktNYBALAwKnIAgD3QWgcAwLoMj0eGidZ6pD5+RmsdAAALoyIHANgDrXUAACzMY0iO6EvktNYBALAwKnIAgD0YhiQzz5FHZkVOIgcA2ILhMWSYaK0bJHIAAMLI8MhcRc7jZwAAIMioyAEAtkBrHQAAK4vS1rqlE/nx344ajPowRwKETkVlZP7jAQRDxdHGn+/TUe02qN7U+2AaFJm5xtKJvLKyUpL0ft0rYY4ECJ3WPcIdARB6lZWVSktLC8m1ExISlJGRoQ/K3jR9rYyMDCUkJAQhquBxGJHa9PeDx+PR3r17lZKSIofDEe5wbKGiokJZWVkqLS1VampquMMBgoqf79PPMAxVVlYqMzNTMTGhm3997Ngx1dXVmb5OQkKCEhMTgxBR8Fi6Io+JiVHHjh3DHYYtpaam8g8dohY/36dXqCrxH0pMTIy4BBwsPH4GAICFkcgBALAwEjkC4nQ69cgjj8jpdIY7FCDo+PmGFVl6shsAAHZHRQ4AgIWRyAEAsDASOQAAFkYiBwDAwkjk8Nv8+fOVnZ2txMRE5ebm6v333w93SEBQvPfeexo5cqQyMzPlcDi0YsWKcIcE+I1EDr88//zzysvL0/Tp07Vp0yZddNFFGjFihHbt2hXu0ADTqqqqdM4552jevHnhDgUIGI+fwS8DBw7UeeedpwULFnj39e7dW6NHj1ZhYWEYIwOCy+Fw6JVXXtHo0aPDHQrgFypy/KS6ujpt3LhRw4cP99k/fPhwrV27NkxRAQAkEjn8cODAAbndbrlcLp/9LpdLZWVlYYoKACCRyBGAHy8VaxgGy8cCQJiRyPGT2rVrp9jY2CbVd3l5eZMqHQBwepHI8ZMSEhKUm5ur4uJin/3FxcUaPHhwmKICAEhSXLgDgDVMmTJFv/nNb9S/f38NGjRIixYt0q5du3TbbbeFOzTAtKNHj+qrr77yfi4pKdHmzZvVpk0bderUKYyRAT+Nx8/gt/nz52vWrFnat2+f+vTpoyeffFIXX3xxuMMCTFu9erUuueSSJvvHjx+vpUuXnv6AgACQyAEAsDDGyAEAsDASOQAAFkYiBwDAwkjkAABYGIkcAAALI5EDAGBhJHIAACyMRA4AgIWRyAGT8vPzde6553o/33jjjRo9evRpj2PHjh1yOBzavHnzSY/p0qWLioqK/L7m0qVL1apVK9OxORwOrVixwvR1ADRFIkdUuvHGG+VwOORwOBQfH6+uXbvq3nvvVVVVVcjv/dRTT/n9Wk9/ki8AnAqLpiBq/eIXv9CSJUtUX1+v999/XxMnTlRVVZUWLFjQ5Nj6+nrFx8cH5b5paWlBuQ4A+IOKHFHL6XQqIyNDWVlZGjt2rMaNG+dt7x5vh//5z39W165d5XQ6ZRiGjhw5ot/+9rdKT09Xamqqfv7zn+uzzz7zue4TTzwhl8ullJQUTZgwQceOHfP5/setdY/Ho5kzZ6p79+5yOp3q1KmTZsyYIUnKzs6WJPXr108Oh0NDhw71nrdkyRL17t1biYmJ6tWrl+bPn+9zn08++UT9+vVTYmKi+vfvr02bNgX8dzR79mz17dtXLVq0UFZWliZNmqSjR482OW7FihXq0aOHEhMTNWzYMJWWlvp8//rrrys3N1eJiYnq2rWrHn30UTU0NAQcD4DAkchhG0lJSaqvr/d+/uqrr/TCCy/opZde8ra2r7zySpWVlenNN9/Uxo0bdd555+nSSy/VwYMHJUkvvPCCHnnkEc2YMUMbNmxQ+/btmyTYH5s2bZpmzpyphx56SFu3btXy5cvlcrkkNSZjSfrHP/6hffv26eWXX5YkLV68WNOnT9eMGTO0bds2FRQU6KGHHtKyZcskSVVVVbrqqqvUs2dPbdy4Ufn5+br33nsD/juJiYnRnDlz9K9//UvLli3TO++8o6lTp/ocU11drRkzZmjZsmX68MMPVVFRoeuuu877/d///nddf/31mjx5srZu3aqFCxdq6dKl3l9WAISYAUSh8ePHG6NGjfJ+/vjjj422bdsa11xzjWEYhvHII48Y8fHxRnl5ufeYt99+20hNTTWOHTvmc61u3boZCxcuNAzDMAYNGmTcdtttPt8PHDjQOOecc05474qKCsPpdBqLFy8+YZwlJSWGJGPTpk0++7Oysozly5f77Hv88ceNQYMGGYZhGAsXLjTatGljVFVVeb9fsGDBCa/1Q507dzaefPLJk37/wgsvGG3btvV+XrJkiSHJWLdunXfftm3bDEnGxx9/bBiGYVx00UVGQUGBz3WeffZZo3379t7PkoxXXnnlpPcF0HyMkSNqvfHGG2rZsqUaGhpUX1+vUaNGae7cud7vO3furDPOOMP7eePGjTp69Kjatm3rc52amhp9/fXXkqRt27bptttu8/l+0KBBevfdd08Yw7Zt21RbW6tLL73U77j379+v0tJSTZgwQbfccot3f0NDg3f8fdu2bTrnnHOUnJzsE0eg3n33XRUUFGjr1q2qqKhQQ0ODjh07pqqqKrVo0UKSFBcXp/79+3vP6dWrl1q1aqVt27bpZz/7mTZu3Kj169f7VOBut1vHjh1TdXW1T4wAgo9Ejqh1ySWXaMGCBYqPj1dmZmaTyWzHE9VxHo9H7du31+rVq5tcq7mPYCUlJQV8jsfjkdTYXh84cKDPd7GxsZIkwzCaFc8P7dy5U1dccYVuu+02Pf7442rTpo0++OADTZgwwWcIQmp8fOzHju/zeDx69NFHNWbMmCbHJCYmmo4TwKmRyBG1WrRooe7du/t9/HnnnaeysjLFxcWpS5cuJzymd+/eWrdunW644QbvvnXr1p30mjk5OUpKStLbb7+tiRMnNvk+ISFBUmMFe5zL5VKHDh30zTffaNy4cSe87plnnqlnn31WNTU13l8WThXHiWzYsEENDQ3605/+pJiYxukyL7zwQpPjGhoatGHDBv3sZz+TJG3fvl2HDx9Wr169JDX+vW3fvj2gv2sAwUMiB7532WWXadCgQRo9erRmzpypnj17au/evXrzzTc1evRo9e/fX3fffbfGjx+v/v3768ILL9Rzzz2nLVu2qGvXrie8ZmJiou6//35NnTpVCQkJuuCCC7R//35t2bJFEyZMUHp6upKSkrRy5Up17NhRiYmJSktLU35+viZPnqzU1FSNGDFCtbW12rBhgw4dOqQpU6Zo7Nixmj59uiZMmKAHH3xQO3bs0B//+MeA/rzdunVTQ0OD5s6dq5EjR+rDDz/U008/3eS4+Ph43XXXXZozZ47i4+N155136vzzz/cm9ocfflhXXXWVsrKydPXVVysmJkb//Oc/9fnnn+v3v/994P8hAASEWevA9xwOh958801dfPHFuvnmm9WjRw9dd9112rFjh3eW+bXXXquHH35Y999/v3Jzc7Vz507dfvvtp7zuQw89pHvuuUcPP/ywevfurWuvvVbl5eWSGsef58yZo4ULFyozM1OjRo2SJE2cOFHPPPOMli5dqr59+2rIkCFaunSp93G1li1b6vXXX9fWrVvVr18/TZ8+XTNnzgzoz3vuuedq9uzZmjlzpvr06aPnnntOhYWFTY5LTk7W/fffr7Fjx2rQoEFKSkrS3/72N+/3l19+ud544w0VFxdrwIABOv/88zV79mx17tw5oHgANI/DCMZgGwAACAsqcgAALIxEDgCAhZHIAQCwMBI5AAAWRiIHAMDCSOQAAFgYiRwAAAsjkQMAYGEkcgAALIxEDgCAhZHIAQCwsP8PMRqwlkK/nqkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "test_probs = model.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "train_pred =  model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "print(f'Precision: {precision_score(y_test, test_pred):.2f}')\n",
    "print(f'Recall: {recall_score(y_test, test_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Randomly split the *training* data into a *train* and *validation* set; similar to how you [randomly split the original dataset](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with 30% of the training data (equals 70% times 30% = 21% of the overall data) reserved for the validation set. Use a random seed of `2024` for reproducibility of the results.\n",
    "\n",
    "Build a [logistic regression model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#logisticregression) on the train set with the parameter setting `penalty = 'None'` (this will train a basic model without applying any regularization). \n",
    "\n",
    "Evaluate the [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) of your model on both (a) the train set, and (b) the validation set. Report your results and briefly explain whether you find evidence of *overfitting*, along with a brief description of what that means. \n",
    "\n",
    "If you do find evidence of overfitting, retrain the model (potentially multiple times) to reduce the overfitting by changing the `penalty` parameter to `l2` (this is the default) and trying different values of the `C` hyperparameter that controls the strength of regularization. Show your work and explain in English how you decided on a good setting of the hyperparameter `C` controlling the degree of regularization. \n",
    "\n",
    "You should conclude this task by reporting a final model that achieves comparable accuracy on the train set as the unregularized model and that mitigates any evidence of overfitting (it may not be possible to achieve a validation error that is no greater than the train error, but you should reduce the gap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.98\n",
      "Validation Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "x_train2, x_validate, y_train2, y_validate = train_test_split(\n",
    "    X_train, y_train, test_size=0.30, random_state=2024)\n",
    "\n",
    "\n",
    "model2 = LogisticRegression(penalty='l2', max_iter= 50000, solver='liblinear', C=1\n",
    "                           )\n",
    "model2.fit(x_train2, y_train2)\n",
    "training_probs = model2.predict_proba(x_train2)\n",
    "validate_probs = model2.predict_proba(x_validate)\n",
    "\n",
    "train2_pred =  model2.predict(x_train2)\n",
    "validate_pred = model2.predict(x_validate)\n",
    "\n",
    "train_accuracy = acc(y_train2, train2_pred)\n",
    "validate_accuracy = acc(y_validate, validate_pred)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Validation Accuracy: {validate_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1 with penalty equal to none \n",
    "reported:\n",
    "Training Accuracy: 1.00\n",
    "Validation Accuracy: 0.94\n",
    "\n",
    "\n",
    "Test 2 with penalty equal to l2\n",
    "reported:\n",
    "Training Accuracy: 0.98\n",
    "Validation Accuracy: 0.93\n",
    "\n",
    "\n",
    "Test3 with penalty equal to l1\n",
    "reported:\n",
    "Training Accuracy: 0.98\n",
    "Validation Accuracy: 0.93\n",
    "\n",
    "\n",
    "\n",
    "Test 4 with penalty equal to elasticnet\n",
    "reported (results same for all l1 ratio):\n",
    "Training Accuracy: 0.94\n",
    "Validation Accuracy: 0.91\n",
    "\n",
    "\n",
    "C value changes:\n",
    "c= 0->1: c 0.96-0.98 for training accuracy and 0.91-0.93 for validation\n",
    "\n",
    "c= 1: 0.98 for training accuracy and 0.93 for validation\n",
    "\n",
    "c= 2: .97 for training accuracy and 0.93 for validation\n",
    "\n",
    "End: 0.98 for training accuracy and 0.93 for validation\n",
    "\n",
    "\n",
    "There was significant evidence of overfitting when the penalty was equal to none because the model returned the exact values from the training data resulting in a training accuracy of 100% while the validation accuracy was signifigantly worse. \n",
    "\n",
    "When we use the l2 penalties and look at the results from various hyperparameters, it appears best to use the l2 penalty and to set the c value equal to 1 this is because c=1 provided the same training and validation accuracy as much stronger penalties while also reducing the neccessary strenth of penalty. This penalty reduced the evidence of overfitting from not having a penalty by improving the training to validation accuracy gap from 9% to 5% and it retained comparable training accuracy reporting at 98%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "For the final model you trained in task 3, compute and visualize the [confusion matrix](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#create-confusionmatrixdisplay) of the resulting predictions on the test data. Also compute and report the [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) and [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) of the predictions on the test data. \n",
    "\n",
    "Based on your results, briefly describe how the resulting model is an improvement over the baseline from task 2, interpreting the reported metrics in the context of the predictive task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recall_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[1;32m----> 5\u001b[0m ConfusionMatrixDisplay\u001b[38;5;241m.\u001b[39mfrom_estimator(model, x_test, y_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_score(y_test,\u001b[38;5;250m \u001b[39mtest_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall_score(y_test,\u001b[38;5;250m \u001b[39mtest_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(model, x_test, y_test)\n",
    "print(f'Precision: {precision_score(y_test, test_pred):.2f}')\n",
    "print(f'Recall: {recall_score(y_test, test_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model's precision and recall are not significantly better than those of the baseline model. Precision indicates the proportion of true positives among all predicted positives, while recall measures the proportion of true positives among all actual positives. Stagnancy in these metrics suggest that neither model appears better at correctly identifying malignant tumors and reducing false positives and false negatives compared to one another since our method of optimal hyperparameter control in the end nearly matched the default values of the baseline as well as the results that come from testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "For the predictions of your final model trained in task 3, compute and visualize the [Receiver Operator Characteristic (ROC) Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#roccurvedisplay). Note that you need to use the *probability predictions* of the model, *not* the absolute 0/1 predictions, in order to correctly plot the ROC curve.\n",
    "\n",
    "Briefly interpret the ROC curve. In particular, what change(s) in the model account for the different possible false positive rates and true positive rates represented on the curve? In the context of a cancer detection task, why might one prefer to select a point on the curve other than the default (represented by your previous results in task 4)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_probs_positive = validate_probs[:, 1]\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_validate, validate_probs_positive)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Logistic Regression')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may choose to select a point of the ROC curve as opposed to the default values as the ROC curve represent performance across various threshold values and by visualizing the performance at theese values we may be able to identify a change in value from the default which would improve our performance relative to the task if cancer detection. For example we may want our algorithim to err on the side of additional false positives if it improves the true positive rate as not flagging cancer for detection and leaving it untreated has worse consequences than flagging a sample for additional inspection that winds up being harmless. while this model may be less accurate on some standards as opposed to the default for this specific task it could end up saving lives by being less accurate as a whole.For example we could have a 100% true positive rate if we are willing to have a 30% false positive rate. While this would create additional work for doctors who may have to review samples by hand it would result in 0 cancer cases missed which ultimately seems more valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "In practice, it can be very helpful to under **why** a predictive model made a particular prediction. *Interpretable* models have the property that a human can understand this aspect. One example of an interpretable model is the *decision tree*, especially a *shallow* decision tree.\n",
    "\n",
    "Build three [decision tree classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), one for each setting of the `max_depth` hyperparameter to `3`, `5`, and `7`. Fit each model on the train set from task 3, and evaluate the [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) and [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) of each model on the validation set (also from task 3). \n",
    "\n",
    "Report all of these validation measures for each model corresponding to different settings of `max_depth`, and select one as your final model. Briefly explain why you would select that model for this task. Compute and visualize the [confusion matrix](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#create-confusionmatrixdisplay) of your final decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code for task 6 here\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "max_depths = [3, 5, 7]\n",
    "results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    dt_model = DecisionTreeClassifier(max_depth=max_depth, random_state=2024)\n",
    "    dt_model.fit(X_train_final, y_train_final)\n",
    "    \n",
    "    y_val_pred = dt_model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, average='weighted')  \n",
    "    recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'max_depth': max_depth,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Max Depth: {result['max_depth']}, \"\n",
    "          f\"Accuracy: {result['accuracy']:.4f}, \"\n",
    "          f\"Precision: {result['precision']:.4f}, \"\n",
    "          f\"Recall: {result['recall']:.4f}\")\n",
    "\n",
    "best_model = max(results, key=lambda x: x['accuracy'])\n",
    "print(f\"Selected model: Max Depth {best_model['max_depth']} with Accuracy {best_model['accuracy']:.4f}\")\n",
    "\n",
    "final_model = DecisionTreeClassifier(max_depth=best_model['max_depth'], random_state=2024)\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "y_val_pred_final = final_model.predict(X_val)\n",
    "cm = confusion_matrix(y_val, y_val_pred_final)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the output, we would select the model with max depth 3 because this model achieves the highest accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
